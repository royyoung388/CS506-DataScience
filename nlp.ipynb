{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\97661\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def process_text(df):\n",
    "    df['Summary'].fillna('', inplace=True)\n",
    "    df['Text'].fillna('', inplace=True)\n",
    "    df['Summary'] = df['Summary'].apply(stem_sent)\n",
    "    df['Text'] = df['Text'].apply(stem_sent)\n",
    "    return df\n",
    "\n",
    "\n",
    "def stem_sent(text):\n",
    "    if not text:\n",
    "        return\n",
    "\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    text = text.lower()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    result = []\n",
    "    for w in words:\n",
    "        # remove all punctuation\n",
    "        if w in string.punctuation or w in stopwords.words('english'):\n",
    "            continue\n",
    "        result.append(stemmer.stem(w))\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "def calc_counter(text, vocab_counter):\n",
    "    counter = Counter(text.split())\n",
    "    vocab_counter += counter\n",
    "\n",
    "\n",
    "def one_hot(text, vocabulary):\n",
    "    vec = [0] * (len(vocabulary) + 1)\n",
    "    counter = Counter(text.split())\n",
    "    for k, v in counter.items():\n",
    "        if k in vocabulary:\n",
    "            vec[vocabulary[k]] = v\n",
    "        else:\n",
    "            vec[0] += v\n",
    "    return vec\n",
    "\n",
    "\n",
    "def convert2Id(text, id_dict):\n",
    "    if text in id_dict:\n",
    "        return id_dict[text]\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load files into DataFrames\n",
    "print('loading data...')\n",
    "if os.path.exists('./data/X_train_stem.csv'):\n",
    "    X_train = pd.read_csv(\"./data/X_train_stem.csv\", index_col=0)\n",
    "    X_submission = pd.read_csv(\"./data/X_test_stem.csv\", index_col=0)\n",
    "    X_train[['Summary', 'Text']] = X_train[['Summary', 'Text']].astype(str)\n",
    "    X_submission[['Summary', 'Text']] = X_submission[['Summary', 'Text']].astype(str)\n",
    "else:\n",
    "    X_train = pd.read_csv(\"./data/X_train.csv\", index_col=0)\n",
    "    X_submission = pd.read_csv(\"./data/X_test.csv\", index_col=0)\n",
    "    X_train[['Summary', 'Text']] = X_train[['Summary', 'Text']].astype(str)\n",
    "    X_submission[['Summary', 'Text']] = X_submission[['Summary', 'Text']].astype(str)\n",
    "    # stem word\n",
    "    print('stem data')\n",
    "    X_train = process_text(X_train)\n",
    "    X_train.to_csv(\"./data/X_train_stem.csv\")\n",
    "    X_submission = process_text(X_submission)\n",
    "    X_submission.to_csv(\"./data/X_test_stem.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime(X_train['Time'], unit='s')\n",
    "X_train['Day'] = date.dt.day\n",
    "X_train['Month'] = date.dt.month\n",
    "X_train['Year'] = date.dt.year\n",
    "\n",
    "date = pd.to_datetime(X_submission['Time'], unit='s')\n",
    "X_submission['Day'] = date.dt.day\n",
    "X_submission['Month'] = date.dt.month\n",
    "X_submission['Year'] = date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "    # (preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['ProductId', 'UserId']),\n",
    "    (preprocessing.MinMaxScaler(), ['Day', 'Month', 'Year']), \n",
    "    ('passthrough', ['Helpfulness']),\n",
    "    (TfidfVectorizer(stop_words={'english'}, min_df=10, ngram_range=(1,1)), 'Summary'),\n",
    "    (TfidfVectorizer(stop_words={'english'}, min_df=10, ngram_range=(2,2)), 'Text'),\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[:300]\n",
    "column_trans.fit(x)\n",
    "newdata = column_trans.transform(x)\n",
    "# newdata.toarray()\n",
    "newdata.shape\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60730999 0.6003406  0.6073243  0.60290656 0.61446981 0.62774323\n",
      " 0.63443361 0.64138158 0.65020429 0.65385358]\n",
      "[0.75072966 0.75158037 0.7514937  0.75129911 0.75225636 0.75226431\n",
      " 0.75248851 0.75170459 0.75098825 0.7504985 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    " \n",
    "# steps = make_pipeline(column_trans, ComplementNB())\n",
    "train_set = column_trans.fit_transform(X_train)\n",
    "\n",
    "cv_results = cross_validate(ComplementNB(), train_set, X_train['Score'], cv=10, return_train_score=True, return_estimator=True)\n",
    "print(cv_results['test_score'])\n",
    "print(cv_results['train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cv_results))\n",
    "print(cv_results['test_score'][cv_results['test_score'].argmax()])\n",
    "\n",
    "test_set = column_trans.transform(X_submission)\n",
    "optimal = cv_results['estimator'][cv_results['test_score'].argmax()]\n",
    "X_submission['Score'] = optimal.predict(test_set)\n",
    "X_submission[['Score']].to_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = optimal.predict(train_set)\n",
    "\n",
    "# Plot a confusion matrix\n",
    "cm = confusion_matrix(X_train['Score'], pre, normalize='true')\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('Confusion matrix of the Summary classifier')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58670235 0.58074188 0.58299584 0.57623092 0.59130037 0.60785099\n",
      " 0.61660215 0.61798316 0.62644094 0.62785772]\n",
      "[0.73036996 0.73222323 0.73152756 0.73211372 0.7331942  0.73355754\n",
      " 0.73379923 0.73266629 0.73150551 0.73122486]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 8 \n",
    "tfidf = TfidfVectorizer(stop_words={'english'}, min_df=10, ngram_range=(1,2))\n",
    "data = tfidf.fit_transform(X_train['Text'])\n",
    "\n",
    "cv_results = cross_validate(ComplementNB(), data, X_train['Score'], cv=10, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(cv_results['test_score'])\n",
    "print(cv_results['train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.6278577204067176\n"
     ]
    }
   ],
   "source": [
    "print(len(cv_results))\n",
    "optimal = cv_results['estimator'][cv_results['test_score'].argmax()]\n",
    "print(cv_results['test_score'][cv_results['test_score'].argmax()])\n",
    "\n",
    "testset = tfidf.transform(X_submission['Text'])\n",
    "result = optimal.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57410164 0.56855618 0.58014797 0.58746503 0.5807675  0.58229877\n",
      " 0.58481034 0.58728614 0.58738632 0.58571193]\n",
      "[0.60498863 0.6055078  0.60357583 0.60365406 0.60355865 0.60409929\n",
      " 0.60286696 0.60187314 0.60227385 0.60236687]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm = SGDClassifier()\n",
    "svm_results = cross_validate(svm, data, X_train['Score'], cv=10, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(svm_results['test_score'])\n",
    "print(svm_results['train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57413026 0.56826996 0.58087783 0.58742925 0.58032386 0.58205548\n",
      " 0.58491768 0.58751512 0.58759383 0.58553305]\n",
      "[0.60442892 0.60510948 0.60429058 0.60363895 0.60337976 0.60300609\n",
      " 0.60341475 0.60268489 0.6029234  0.60195662]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(C=1000)\n",
    "svc_results = cross_validate(svm, data, X_train['Score'], cv=10, return_train_score=True, return_estimator=True)\n",
    "\n",
    "print(svc_results['test_score'])\n",
    "print(svc_results['train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pre = \n",
    "\n",
    "# Plot a confusion matrix\n",
    "cm = confusion_matrix(X_train['Score'], y_train, normalize='true')\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('Confusion matrix of the Summary classifier')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e8e723b264b9c7710d9c430787c1b75ff8eb9b97006a27779a2e0cd72ceeaa1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cs506')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
